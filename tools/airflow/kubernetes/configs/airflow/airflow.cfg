[core]
dags_folder = /airlock/dags

executor = KubernetesExecutor
parallelism = 2048
max_active_runs_per_dag=32
dag_concurrency = 256
load_examples = False
load_default_connections = False
plugins_folder = /tiki/airlock/plugins

non_pooled_task_slot_count = 128

default_timezone = Asia/Ho_Chi_Minh
backfill_batch_days = 8

# dag import
dagbag_import_timeout = 120
dags_are_paused_at_creation = True

killed_task_cleanup_time = 3600

min_serialized_dag_update_interval = 5
min_serialized_dag_fetch_interval = 5
hide_sensitive_var_conn_fields = True

[logging]
# logging
base_log_folder = /home/airflow/airflow/logs
remote_logging = True
remote_base_log_folder = gs://tiki_airflow_airlock/logs
remote_log_conn_id = gcp-tiki-dwh
logging_level = INFO
fab_logging_level = WARN
colored_console_log = False

[scheduler]
standalone_dag_processor = False
scheduler_health_check_threshold = 60
catchup_by_default = False
child_process_log_directory = /home/airflow/airflow/logs/scheduler

parsing_processes = 8
max_dagruns_to_create_per_loop = 50
max_dagruns_per_loop_to_schedule = 70

scheduler_heartbeat_sec = 2

run_duration = -1

dag_dir_list_interval = 10
job_heartbeat_sec = 5
# after how much time a new DAGs should be picked up from the filesystem
min_file_process_interval = 5
processor_poll_interval = 1

# How many seconds to wait between file-parsing loops to prevent the logs from being spammed.
min_file_parsing_loop_time = 1

print_stats_interval = 30
scheduler_zombie_task_threshold = 100
max_tis_per_query = 1024

[metrics]
# enable metrics servers
statsd_on = True
statsd_host = airlock-contrib.airlock.svc.cluster.local
statsd_port = 9125
statsd_prefix = airlock


[webserver]
# Use FAB-based webserver with RBAC feature
rbac = True
authenticate = True
# Filter the list of dags by owner name (requires authentication to be enabled)
filter_by_owner = True
enable_proxy_fix = True
proxy_fix_x_for = 1
base_url = https://airlock.tiki.com.vn
worker_class = sync

# Consistent page size across all listing views in the UI
page_size = 25

navbar_color = #d5e8ff

auth_backend = airflow.contrib.auth.backends.google_auth

# Send anonymous user activity to Google Analytics
analytics_tool = google_analytics
analytics_id = UA-134830679-3
default_ui_timezone = Asia/Ho_Chi_Minh

# By default, the webserver shows paused DAGs. Flip this to hide paused
# DAGs by default
hide_paused_dags_by_default = True

workers = 8

web_server_master_timeout = 600
web_server_worker_timeout = 600
# Default DAG view.  Valid values are:
# tree, graph, duration, gantt, landing_times
dag_default_view = tree
# Default DAG orientation. Valid values are:
# LR (Left->Right), TB (Top->Bottom), RL (Right->Left), BT (Bottom->Top)
dag_orientation = LR
# Puts the webserver in demonstration mode; blurs the names of Operators for
# privacy.
demo_mode = False
# The amount of time (in secs) webserver will wait for initial handshake
# while fetching logs from other worker machine
log_fetch_timeout_sec = 30


[kubernetes]
# must config to mount the template
pod_template_file = /home/airflow/pod_template.yml
worker_container_repository = asia.gcr.io/tikivn/airlock
worker_container_tag = release
namespace = airlock
delete_worker_pods = True
delete_worker_pods_on_failure = True
dags_in_image = False
in_cluster = True
worker_pods_creation_batch_size = 32

[cli]
# directly access to db
api_client = airflow.api.client.local_client

[api]
auth_backend = airflow.api.auth.backend.basic_auth

[database]
sql_alchemy_max_overflow = 100
sql_alchemy_pool_enabled = True
sql_alchemy_pool_recycle = 300
sql_alchemy_pool_size = 400
